CMPT 383 Project - Visualizing shares of popular programming languages

##################### Languages overview #####################

Python - Webscraping with BeautifulSoup

Julia - for Plotting the Data

C/C++ - Some alteration(filters) of image and Conversion to jpg of Visualized Data

==============================================================



######################## Instructions ########################

To access my project, turn on a vm by using "vagrant up" and "varant ssh" to access the vm's terminal

Once in the terminal of the vm, "cd project/project" to access my project folder

Then, "julia setup.jl" to install 3 julia libraries, two for plotting and another for calling python functions/scripts. 
Continuing, "julia plot.jl" will run a julia script that calls a python script within itself that 
produces a pie chart using web scraped data from the python script and sends the pie chart to a "pie.png" files - Note: This takes quite awhile as julia needs to preload the libraries everytime.

Next, "make convert" to complie the image processor and "./convert" to produce a variety of "pie.png" in the form of gray scaled and jpgs
The expected output can be seen in the expected_images folder


More Detailed instructions on running my program: 
    Note: instructions with "*" dont need to be ran if vagrant provision properly executed the contents of "default.rb"
    /////// install Python library ///////
    *sudo apt install python*
    *sudo apt install python3-pip*
    *pip3 install bs4*
    //////////////////////////////////////

    cd project/project

    python3 scrape.py - not necessary since its called within Julia, can run to see output

    /////// install Julia packages ///////
    *cd*
    *wget https://julialang-s3.julialang.org/bin/linux/x64/1.4/julia-1.4.2-linux-x86_64.tar.gz*
    *tar -xvzf julia-1.4.2-linux-x86_64.tar.gz*
    *sudo cp -r julia-1.4.2 /opt/*
    *sudo ln -s /opt/julia-1.4.2/bin/julia /usr/local/bin/julia*
    *cd project/project*
    //////////////////////////////////////

    julia setup.jl - downloads the necessary libraries
    julia plot.jl - calls the Python script,for the data and outputs a pie chart "pie.png"

    //////// install gcc /////////
    *sudo apt install gcc*
    *sudo apt install zlib1g*
    //////////////////////////////

    make convert
    ./convert 

    -> there will now be the 4 images in the same directory as the source files, namely,
    "pie.png","pie.jpg","pie_gray.png" and "pie_gray.jpg"

==============================================================


######################## Description #########################

This collection of programs aims to visualize the "popularity" of languages and output an archiveble compressed visual representation.
I used Python to scrape Github's repository for the number of public projects created in the month of July 2020 and passed the data on to Julia to visualize said data.
The Raw data and visualized data are then passed onto C++ as files that are compressed using Huffman trees

I used PyCall as a method to call my python script to scrape the web for relevent data directly from my Julia script.
Note: It did not work out as expected as the bs4 library could not be found within julia, hence the bruteforce data entry. 
(Running the Python script independently gives teh expected results)
I'm not too sure why this problems arise, but was not able to find a solution online after 
spending several hours iusolating the problem and looking for soluitions.

The C++ program simply looks for a png named "pie.png" located in the same library produced by my Julia script to produce similar jpg and filtered versions of pie.png

"compress.c" was my attempt to compress the resulting 4 images in the file but came across a link error that I wasnt able to fix after two hours.

==============================================================

######################## Post-Mortem #########################
Though this is a relatively simple project, a significant amount of time was spent reading up and learning 
how to scrape information from the web and choosing a language which can facilitate this easily.
My first attempts involved Java/Javascript and reading much lower quality documentation on web scraping compared to that of python's.
Thus, the decision to use python for web scraping.

As Visuals tend to be more intuitive and easier to understand, I wanted to visualize the data pulled from web scraping.
I ended up using Julia as it has a Plots library which I had some experience with when doing assignment 2.

To compress the results, I utilized C as it is one of the languages that I have most experience with and also one of the most optimizaed for this task.
This, along with the integration of languages were the toughest part, having to understand extract information from png and reconstructing it in another format.
Though the raw code is rather short, a significant anount of time was needed to find and understand the required functions of the libraries. 
Resources which helped in understanding: 

Throughout the project, Python seems to be able to do all tasks adequately, potentially rendering the use of other languages pointless.
In my case, I do not think the use of three languages were justified as the run time and the amount of time spent figuring out how to integrate 
the three languages combined far exceeds the time required to accomplish the same with a program fully built with python.

Potential Improvements/Extensions:
 - Extract monthly data for the past year instead of just one
 - Scrape from more sites than Github
 - more types of graphs/charts
 - more descriptive chart
 - finish the compression
==============================================================